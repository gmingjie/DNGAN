# Deep Convolutional Neural Network With Adversarial Training for Denoising Digital Breast Tomosynthesis Images 

This repository is for the paper: 

M. Gao, J. A. Fessler, and H.-P. Chan, "Deep Convolutional Neural Network With Adversarial Training for Denoising Digital Breast Tomosynthesis Images", _IEEE Transactions on Medical Imaging_, 2021. DOI: [10.1109/TMI.2021.3066896](https://doi.org/10.1109/TMI.2021.3066896). 

## Data

The training data is prepared using simulation software. 
* The breast phantoms are generated by [VICTRE](https://github.com/DIDSR/VICTRE). 
* We use the private Matlab-based CatSim from GE to simulate the GE Pristina DBT system. Although an open-source [Python-based CatSim](https://github.com/xcist/CatSim) is recently available, it has not included all the modules. As an alternative, one can use [MC-GPU](https://github.com/DIDSR/VICTRE_MCGPU) in the VICTRE package to generate the PVs. 
* We reconstruct the DBTs using our own SART algorithm and SG projector. If you do not have an available recon algorithm, you can try the FBP algorithm in the VICTRE package. 

## Code 

### Requirement
Python 2.7, TensorFlow 1.4.1. 

### Training
We are cleaning up the training code and will publish it later. Our training code is developed based on the following repos and you may find them useful: [improved_wgan_training](https://github.com/igul222/improved_wgan_training), [MAP-NN](https://github.com/hmshan/MAP-NN).  
### Deployment
To deploy the denoiser, run: 
```
python deploy_dngan.py
```
We provide part of a reconstructed VICTRE phantom DBT image (hetero, with some MCs) as an example for testing the deployment code. The `.rawg` format is our customized image format. To import the image into ImageJ, use: image type `32-bit real`, width `640` pixels, height `975` pixels, offset to first image `1024` bytes, number of images `5`, little-endian byte order. 

## Trained models

We provide the following trained models that are mentioned in the paper: 24mAs/120mAs, 24mAs/noiseless. 

### Limitation
These trained denoiser models are not very general and are meant to be used only within a certain noise range. The reason is that the training data only contains hetero DBTs that are 4.5cm thick, have 24mAs exposure, and are reconstructed by 3 iterations of SART. We are working on making the denoiser to cover a wider range of noise levels and be more robust. 

