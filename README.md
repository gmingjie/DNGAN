# Deep Convolutional Neural Network With Adversarial Training for Denoising Digital Breast Tomosynthesis Images 

This repository is for the paper: 

M. Gao, J. A. Fessler, and H.-P. Chan, "Deep Convolutional Neural Network With Adversarial Training for Denoising Digital Breast Tomosynthesis Images", _IEEE Transactions on Medical Imaging_, 2021. DOI: [10.1109/TMI.2021.3066896](https://doi.org/10.1109/TMI.2021.3066896). 

## Data

The training data is prepared using simulation software. 
* The breast phantoms are generated by [VICTRE](https://github.com/DIDSR/VICTRE). 
* We use the private Matlab-based CatSim from GE to simulate the GE Pristina DBT system. Although an open-source [Python-based CatSim](https://github.com/xcist/CatSim) is recently available, it has not included all the modules. As an alternative, one can use [MC-GPU](https://github.com/DIDSR/VICTRE_MCGPU) in the VICTRE package to generate the PVs. 
* We reconstruct the DBTs using our own SART algorithm and [SG projector](https://doi.org/10.1002/mp.12092). If you do not have an available recon algorithm, you can try the FBP algorithm in the VICTRE package. 

## Code 

### Requirement
Python 2.7, TensorFlow 1.4.1. 

### Training
The training code is developed based on the following repos and you may find them useful when you develop your training code: [improved_wgan_training](https://github.com/igul222/improved_wgan_training), [MAP-NN](https://github.com/hmshan/MAP-NN).  
### Deployment
To deploy the denoiser, run: 
```
python deploy_dngan.py
```
We provide 5 slices of a reconstructed VICTRE phantom DBT image (hetero, with some MCs) as an example for testing the deployment code. The `.rawg` format is our customized image format. To import the image into ImageJ, use: image type `32-bit real`, width `640` pixels, height `975` pixels, offset to first image `1024` bytes, number of images `5`, little-endian byte order. 

## Pre-trained models

We provide the following trained models: 24mAs/120mAs, 24mAs/noiseless. 

### Limitation
The denoiser models are still under development. These preliminary trained denoiser models are not general and may be applicable to images within a certain noise range only because of the limited conditions of the training data. Please refer to the published paper for details. 
